diffkernels <- c("rbfdot","splinedot","laplacedot","polydot","vanilladot")
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#create a dataframe to store the data from the for loop
results2 <- data.frame("C-Values" = integer(),"accuracy" = numeric(),"kernel_name" = character(),stringsAsFactors = FALSE)
#n starts from 0.
n <- 0
for (ikernel in diffkernels) {
n <- n+1
for(cvalue in cvalues)
{
#setup linear equation for kernel we want to use in this question,loop for different kernels and c valuse.
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),
type='C-svc',kernel=ikernel,C=cvalue,scaled=TRUE)
#use ksvm to run formular in different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#need function to contain value
results2[nrow(results) + 1,] <- c(cvalue,accuracy,ikernel)
}
}
# we find out the highest accuracy rate is 0.8639. Where the c value in between 0.01 - 100.
#Therefore, the best c vaule of this model we can pick from 0.01-100 to get the highest accuracy rate.
View(results2)
library(kernlab)
#import data from txt.
data <- read.table("credit_card_data.txt", header = FALSE)
setwd("~/Desktop/ISY_6501/hw1-SP22/data 2.2")
library(kernlab)
#import data from txt.
data <- read.table("credit_card_data.txt", header = FALSE)
library(kernlab)
#import data from txt.
data <- read.table("credit_card_data.txt", header = FALSE)
#import data from txt.
data <- read.table("credit_card_data.txt", header = FALSE)
#import data from txt.
data <- read.table("credit_card_data.txt", header = FALSE)
#try different methods other than vanilladot
diffkernels <- c("rbfdot","splinedot","laplacedot","polydot","vanilladot")
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#create a dataframe to store the data from the for loop
results2 <- data.frame("C-Values" = integer(),"accuracy" = numeric(),"kernel_name" = character(),stringsAsFactors = FALSE)
#n starts from 0.
n <- 0
for (ikernel in diffkernels) {
n <- n+1
for(cvalue in cvalues)
{
#setup linear equation for kernel we want to use in this question,loop for different kernels and c valuse.
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),
type='C-svc',kernel=ikernel,C=cvalue,scaled=TRUE)
#use ksvm to run formular in different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#need function to contain value
results2[nrow(results) + 1,] <- c(cvalue,accuracy,ikernel)
}
}
# we find out the highest accuracy rate is 0.8639. Where the c value in between 0.01 - 100.
#Therefore, the best c vaule of this model we can pick from 0.01-100 to get the highest accuracy rate.
View(results2)
#2.2.2 (Optional)
#try different methods other than vanilladot
diffkernels <- c("rbfdot","splinedot","laplacedot","polydot","vanilladot")
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#setup linear equation for kernel we want to use in this question
#create a dataframe to store the data from the for loop
results2 <- data.frame("C-Values" = integer(),"accuracy" = numeric(),"kernel_name" = character(),stringsAsFactors = FALSE)
n <- 0
for (ikernel in diffkernels) {
n <- n+1
for(cvalue in cvalues)
{
#test the c values in model
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type='C-svc',kernel=ikernel,C=cvalue,scaled=TRUE)
#use ksvm to run formular in different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#need function to contain value
results2[nrow(results) + 1,] <- c(cvalue,accuracy,ikernel)
}
}
# we find out the highest accuracy rate is 0.8639. Where the c value in between 0.01 - 100.
#Therefore, the best c vaule of this model we can pick from 0.01-100 to get the highest accuracy rate.
View(results2)
#2.2.2 (Optional)
#try different methods other than vanilladot
diffkernels <- c("rbfdot","splinedot","laplacedot","polydot","vanilladot")
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#setup linear equation for kernel we want to use in this question
#create a dataframe to store the data from the for loop
results <- data.frame("C-Values" = integer(),"accuracy" = numeric(),"kernel_name" = character(),stringsAsFactors = FALSE)
n <- 0
for (ikernel in diffkernels) {
n <- n+1
for(cvalue in cvalues)
{
#test the c values in model
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type='C-svc',kernel=ikernel,C=cvalue,scaled=TRUE)
#use ksvm to run formular in different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#need function to contain value
results[nrow(results) + 1,] <- c(cvalue,accuracy,ikernel)
}
}
# we find out the highest accuracy rate is 0.8639. Where the c value in between 0.01 - 100.
#Therefore, the best c vaule of this model we can pick from 0.01-100 to get the highest accuracy rate.
View(results)
#try different methods other than vanilladot
diffkernels <- c("rbfdot","splinedot","laplacedot","polydot","vanilladot")
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#create a dataframe to store the data from the for loop
results <- data.frame("C-Values" = integer(),"accuracy" = numeric(),"kernel_name" = character(),stringsAsFactors = FALSE)
#n starts from 0.
n <- 0
for (ikernel in diffkernels) {
n <- n+1
for(cvalue in cvalues)
{
#setup linear equation for kernel we want to use in this question,loop for different kernels and c valuse.
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),
type='C-svc',kernel=ikernel,C=cvalue,scaled=TRUE)
#use ksvm to run formular in different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#need function to contain value
results[nrow(results) + 1,] <- c(cvalue,accuracy,ikernel)
}
}
# we find out the highest accuracy rate is 0.8639. Where the c value in between 0.01 - 100.
#Therefore, the best c vaule of this model we can pick from 0.01-100 to get the highest accuracy rate.
View(results)
#Elbow Plot:  accuracy vs. K-values
par(bg="white")
plot(kknn_accuracy,ylab="accuracy level",xlab="K values" ,type='b',col='blue', main='Fig: KKN accuracy')
install.packages("tinytex")
#install.packages("tinytex")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
#install.packages("tinytex")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("XQuartz")
library(kknn)
#import data
knndata <- read.table("credit_card_data.txt", header = FALSE,stringsAsFactors = FALSE)
head(knndata)
#create function to run for the train and test value, get the accuracy rate
accuracy_check = function(X){
predicted <- rep(0,(nrow(data)))
for (i in 1:nrow(data))
{
#define model for calculation
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X, scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
# generate number from 1-20 of k values to test accuracy rate
kknn_accuracy<- rep(0,20)
for (i in 1:20)
{
#looping k value
kknn_accuracy[i] <- accuracy_check(i)
}
max(kknn_accuracy)
max(kknn_accuracy,i)
View(result)
results <- data.frame("best_k_value" = integer(),"max_accuracy" = numeric(),stringsAsFactors = FALSE)
knndata <- read.table("credit_card_data.txt", header = FALSE,stringsAsFactors = FALSE)
head(knndata)
knn_result <- data.frame("best_k_value" = integer(),"max_accuracy" = numeric(),stringsAsFactors = FALSE)
#create function to run for the train and test value
accuracy_check = function(X){
predicted <- rep(0,(nrow(data)))
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X, scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
# no.from 1-20 of k values to test
kknn_accuracy<- rep(0,20)
for (i in 1:20)
{
kknn_accuracy[i] <- check_accuracy(i)
knn_result <- c(max(kknn_accuracy))
}
View(knn_result)
accuracy_check = function(X){
predicted <- rep(0,(nrow(data)))
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
accuracy
library(kknn)
knndata <- read.table("credit_card_data.txt", header = FALSE,stringsAsFactors = FALSE)
head(knndata)
knn_result <- data.frame("best_k_value" = integer(),"max_accuracy" = numeric(),stringsAsFactors = FALSE)
#create function to run for the train and test value
accuracy_check = function(X){
predicted <- rep(0,(nrow(data)))
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
# no.from 1-20 of k values to test
kknn_accuracy<- rep(0,20)
for (i in 1:20)
{
kknn_accuracy[i] <- check_accuracy(i)
knn_result <- c(kknn_accuracy,kknn_accuracy[i])
}
View(knn_result)
# no.from 1-20 of k values to test
kknn_accuracy<- rep(0,20)
for (i in 1:20)
{
kknn_accuracy[i] <- check_accuracy(i)
knn_result <- c(kknn_accuracy)
}
View(knn_result)
print("The highest kknn accuracy rate is", max(kknn_accuracy))
#2.2.3
library(kknn)
knndata <- read.table("credit_card_data.txt", header = FALSE,stringsAsFactors = FALSE)
head(knndata)
knn_result <- data.frame("best_k_value" = integer(),"max_accuracy" = numeric(),stringsAsFactors = FALSE)
#general kvalue from 1 to 20
#create function to run for the train and test value
accuracy_check = function(X){
predicted <- rep(0,(nrow(data)))
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
# no.from 1-20 of k values to test
kknn_accuracy<- rep(0,20)
for (i in 1:20)
{
kknn_accuracy[i] <- check_accuracy(i)
knn_result <- c(kknn_accuracy)
}
max_k <- which.max(knn_result$kknn_accuracy)
View(knn_result)
max_k <- which.max(knn_result$kknn_accuracy)
max_k <- which.max(knn_result,getElement(kknn_accuracy))
max_k <- which.max(knn_result,getElement(knn_result))
max_k <- which.max(knn_result,getElement(i))
max_k <- which.max(knn_result,i)
#create function to run for the train and test value
accuracy_check = function(X){
predicted <- rep(0,(nrow(data)))
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
# no.from 1-20 of k values to test
kknn_accuracy<- rep(0,20)
for (i in 1:20)
{
kknn_accuracy[i] <- accuracy_check(i)
knn_result <- c(kknn_accuracy)
}
View(knn_result)
max_k <- which.max(knn_result,kknn_accuracy[i])
#define kknn mode
predicted <- rep(0,(nrow(knndata)))
#create function to run for the train and test value
for(x in 1:20){
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
print("Accuracy",max(accuracy),"best k value is ", x)
}
#define kknn mode
predicted <- rep(0,(nrow(knndata)))
#create function to run for the train and test value
for(X in 1:20){
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
print("Accuracy",max(accuracy),"best k value is ", X)
}
print(("Accuracy",max(accuracy),"best k value is ", X))
print("Accuracy",accuracy,"best k value is ", X)
print(paste0("Accuracy rate: ",accuracy," K = ", X))
predicted <- rep(0,(nrow(knndata)))
#create function to run for the train and test value
for(X in 1:20){
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
print(paste0("Accuracy rate: ",accuracy," K = ", X))
}
accuracydf <- data.frame(accuracy)
View(accuracydf)
predicted <- rep(0,(nrow(knndata)))
#create function to run for the train and test value
for(X in 1:20){
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
print(paste0("Accuracy rate: ",accuracy," K = ", X))
}
accuracydf <- data.frame(accuracy)
View(accuracydf)
max(accuracy)
knndata <- read.table("credit_card_data.txt", header = FALSE,stringsAsFactors = FALSE)
head(knndata)
#create function to run for the train and test value
accuracy_check = function(X){
predicted <- rep(0,(nrow(knndata)))
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
kknn_accuracy <- rep(0,20)
for (i in 1:20) {
kknn_accuracy[i] <- accuracy_check(i)
}
kknn_result <- data.frame(kknn_accuracy)
View(kknn_result)
max_k <- which.max(knn_result$kknn_accuracy)
best_kvalue <- which.max(kknn_accuracy)
View(best_kvalue)
max(kknn_accuracy)
print("The highest kknn accuracy rate is", max(kknn_accuracy), "and the best k value is ", max_k)
print("The highest kknn accuracy rate is", max(kknn_accuracy), "and the best k value is ", best_kvalue)
print(paste0("The highest kknn accuracy rate is", max(kknn_accuracy), "and the best k value is ", best_kvalue))
print(paste0("The highest kknn accuracy rate is", max(kknn_accuracy), " and the best k value is ", best_kvalue))
print(paste0("The highest kknn accuracy rate is ", max(kknn_accuracy), " and the best k value is ", best_kvalue))
plot(kknn_accuracy,ylab="accuracy level",xlab="K values" ,type='b',col='blue', main='KKN accuracy',
scale(break = seq(1,20,by = 1)))
plot(kknn_accuracy,ylab="accuracy level",xlab="K values" ,type='b',col='blue', main='KKN accuracy',
scale(breaks = seq(1,20,by = 1)))
plot(kknn_accuracy,ylab="accuracy level",xlab="K values" ,type='b',col='blue', main='KKN accuracy')
#label
text(best_kvalue, labels = "Best K value", col = "red")
par(bg="white")
plot(kknn_accuracy,ylab="accuracy level",xlab="K values" ,type='b',col='blue', main='KKN accuracy')
#label
text(best_kvalue, labels = "Best K value", col = "red")
#try different methods other than vanilladot
diffkernels <- c("rbfdot","splinedot","laplacedot","polydot","vanilladot")
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#create a dataframe to store the data from the for loop
results <- data.frame("C-Values" = integer(),"accuracy" = numeric(),"kernel_name" = character(),stringsAsFactors = FALSE)
#n starts from 0.
n <- 0
for (ikernel in diffkernels) {
n <- n+1
for(cvalue in cvalues)
{
#setup linear equation for kernel we want to use in this question,loop for different kernels and c valuse.
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type='C-svc',kernel=ikernel,C=cvalue,scaled=TRUE)
#use ksvm to run formular in different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#need function to contain value
results[nrow(results) + 1,] <- c(cvalue,accuracy,ikernel)
}
}
library(kernlab)
#import data from txt.
data <- read.table("credit_card_data.txt", header = FALSE)
#define ksvm function. Call the linear equation to find the best C-value
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type='C-svc',kernel='vanilladot',C=10000,scaled=TRUE)
# calculate a1…am
a <- colSums(model@xmatrix[[1]] * model@coef[[1]])
a
# calculate a0
a0 <- -model@b
a0
# see what the model predicts
pred <- predict(model,data[,1:10])
pred
# see what fraction of the model’s predictions match the actual classification
sum(pred == data[,11]) / nrow(data)
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#setup linear equation for kernel we want to use in this question
k_kernel = 'vanilladot'
#create a dataframe to store the data from the for loop
results <- data.frame("C-Values" = integer(),"accuracy" = numeric())
for(cvalue in cvalues)
{
#create a ksvm model to run for the test.
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type='C-svc',kernel=k_kernel,C=cvalue,scaled=TRUE)
#use ksvm to run formula and loop for different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#create an empty list to store output values
results[nrow(results) + 1,] <- c(cvalue,accuracy)
}
# we find out the highest accuracy rate is 0.8639. Where the c value in between 0.01 - 100.
#Therefore, the best c vaule of this model we can pick from 0.01-100 to get the highest accuracy rate.
View(results)
#try different methods other than vanilladot
diffkernels <- c("rbfdot","splinedot","laplacedot","polydot","vanilladot")
#for loop for different c values
cvalues <- c(0.00001,0.0001,0.01,1,10,100,10000,1000000)
#create a dataframe to store the data from the for loop
results <- data.frame("C-Values" = integer(),"accuracy" = numeric(),"kernel_name" = character(),stringsAsFactors = FALSE)
#n starts from 0.
n <- 0
for (ikernel in diffkernels) {
n <- n+1
for(cvalue in cvalues)
{
#setup linear equation for kernel we want to use in this question,loop for different kernels and c valuse.
model <- ksvm(as.matrix(data[,1:10]),as.factor(data[,11]),type='C-svc',kernel=ikernel,C=cvalue,scaled=TRUE)
#use ksvm to run formular in different c value.
pred <- predict(model,data[,1:10])
#result in fraction of the model’s predictions match the actual classification
accuracy <- sum(pred == data[,11]) / nrow(data)
#need function to contain value
results[nrow(results) + 1,] <- c(cvalue,accuracy,ikernel)
}
}
#We find out the highest accuracy rate is 0.8639. Where the c value in between 0.01 - 100.The best model for this test is rbfdot.
View(results)
library(kknn)
knndata <- read.table("credit_card_data.txt", header = FALSE,stringsAsFactors = FALSE)
head(knndata)
#create function to run for the train and test value
accuracy_check = function(X){
predicted <- rep(0,(nrow(knndata)))
for (i in 1:nrow(data))
{
knn_credit=kknn(V11~.,knndata[-i,],knndata[i,],k=X,distance = 2,scale = TRUE)
predicted[i] <- as.integer(fitted(knn_credit)+0.5) # round off to 0 or 1
}
# calculate % of correct predictions
accuracy<- sum(predicted == knndata[,11]) / nrow(data)
return(accuracy)
}
kknn_accuracy <- rep(0,20)
for (i in 1:20) {
kknn_accuracy[i] <- accuracy_check(i)
}
kknn_result <- data.frame(kknn_accuracy)
View(kknn_result)
best_kvalue <- which.max(kknn_accuracy)
View(best_kvalue)
print(paste0("The highest kknn accuracy rate is ", max(kknn_accuracy), " and the best k value is ", best_kvalue))
#Plot the graph for accuracy vs. K-values
par(bg="white")
plot(kknn_accuracy,ylab="accuracy level",xlab="K values",type='b',col='blue', main='KKN accuracy')
